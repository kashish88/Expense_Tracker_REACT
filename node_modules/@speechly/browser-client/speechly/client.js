"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const locale_code_1 = __importDefault(require("locale-code"));
const uuid_1 = require("uuid");
const microphone_1 = require("../microphone");
const websocket_1 = require("../websocket");
const storage_1 = require("../storage");
const types_1 = require("./types");
const state_1 = require("./state");
const segment_1 = require("./segment");
const parsers_1 = require("./parsers");
const async_retry_1 = __importDefault(require("async-retry"));
const deviceIdStorageKey = 'speechly-device-id';
const authTokenKey = 'speechly-auth-token';
const defaultApiUrl = 'wss://api.speechly.com/ws/v1';
const defaultLoginUrl = 'https://api.speechly.com/login';
const defaultLanguage = 'en-US';
/**
 * A client for Speechly Spoken Language Understanding (SLU) API. The client handles initializing the microphone
 * and websocket connection to Speechly API, passing control events and audio stream to the API, reading the responses
 * and dispatching them, as well as providing a high-level API for interacting with so-called speech segments.
 * @public
 */
class Client {
    constructor(options) {
        var _a, _b, _c, _d, _e, _f, _g, _h, _j;
        this.activeContexts = new Map();
        this.reconnectAttemptCount = 5;
        this.reconnectMinDelay = 1000;
        this.contextStopDelay = 250;
        this.state = types_1.ClientState.Disconnected;
        this.stateChangeCb = () => { };
        this.segmentChangeCb = () => { };
        this.tentativeTranscriptCb = () => { };
        this.tentativeEntitiesCb = () => { };
        this.tentativeIntentCb = () => { };
        this.transcriptCb = () => { };
        this.entityCb = () => { };
        this.intentCb = () => { };
        this.handleWebsocketResponse = (response) => {
            var _a;
            if (this.debug) {
                console.log('[SpeechlyClient]', 'Received response', response);
            }
            // eslint-disable-next-line @typescript-eslint/camelcase
            const { audio_context, segment_id, type } = response;
            let { data } = response;
            const context = this.activeContexts.get(audio_context);
            if (context === undefined) {
                console.warn('[SpeechlyClient]', 'Received response for non-existent context', audio_context);
                return;
            }
            let segmentState = (_a = context.get(segment_id)) !== null && _a !== void 0 ? _a : new segment_1.SegmentState(audio_context, segment_id);
            switch (type) {
                case websocket_1.WebsocketResponseType.TentativeTranscript:
                    data = data;
                    const words = parsers_1.parseTentativeTranscript(data);
                    this.tentativeTranscriptCb(audio_context, segment_id, words, data.transcript);
                    segmentState = segmentState.updateTranscript(words);
                    break;
                case websocket_1.WebsocketResponseType.Transcript:
                    data = data;
                    const word = parsers_1.parseTranscript(data);
                    this.transcriptCb(audio_context, segment_id, word);
                    segmentState = segmentState.updateTranscript([word]);
                    break;
                case websocket_1.WebsocketResponseType.TentativeEntities:
                    data = data;
                    const entities = parsers_1.parseTentativeEntities(data);
                    this.tentativeEntitiesCb(audio_context, segment_id, entities);
                    segmentState = segmentState.updateEntities(entities);
                    break;
                case websocket_1.WebsocketResponseType.Entity:
                    data = data;
                    const entity = parsers_1.parseEntity(data);
                    this.entityCb(audio_context, segment_id, entity);
                    segmentState = segmentState.updateEntities([entity]);
                    break;
                case websocket_1.WebsocketResponseType.TentativeIntent:
                    data = data;
                    const tentativeIntent = parsers_1.parseIntent(data, false);
                    this.tentativeIntentCb(audio_context, segment_id, tentativeIntent);
                    segmentState = segmentState.updateIntent(tentativeIntent);
                    break;
                case websocket_1.WebsocketResponseType.Intent:
                    data = data;
                    const intent = parsers_1.parseIntent(data, true);
                    this.intentCb(audio_context, segment_id, intent);
                    segmentState = segmentState.updateIntent(intent);
                    break;
                case websocket_1.WebsocketResponseType.SegmentEnd:
                    segmentState = segmentState.finalize();
                    break;
                default:
                // TODO: handle unexpected response types.
            }
            // Update the segment in current context.
            context.set(segment_id, segmentState);
            // Update current contexts.
            this.activeContexts.set(audio_context, context);
            // Fire segment change event.
            this.segmentChangeCb(segmentState.toSegment());
        };
        this.handleWebsocketClosure = (err) => {
            if (this.debug) {
                console.error('[SpeechlyClient]', 'Server connection closed', err);
            }
            // If for some reason deviceId is missing, there's nothing else we can do but fail completely.
            if (this.deviceId === undefined) {
                this.setState(types_1.ClientState.Failed);
                return;
            }
            // Make sure we don't have concurrent reconnection procedures or attempt to reconnect from a failed state.
            if (this.state === types_1.ClientState.Connecting || this.state === types_1.ClientState.Failed) {
                return;
            }
            this.setState(types_1.ClientState.Connecting);
            this.reconnectWebsocket(this.deviceId)
                .then(() => this.setState(types_1.ClientState.Connected))
                .catch(() => this.setState(types_1.ClientState.Failed));
        };
        this.handleMicrophoneAudio = (audioChunk) => {
            if (this.state !== types_1.ClientState.Recording) {
                return;
            }
            this.websocket.sendAudio(audioChunk);
        };
        const language = (_a = options.language) !== null && _a !== void 0 ? _a : defaultLanguage;
        if (!locale_code_1.default.validate(language)) {
            throw Error(`[SpeechlyClient] Invalid language "${language}"`);
        }
        this.debug = (_b = options.debug) !== null && _b !== void 0 ? _b : false;
        this.appId = options.appId;
        this.microphone = (_c = options.microphone) !== null && _c !== void 0 ? _c : new microphone_1.BrowserMicrophone((_d = options.sampleRate) !== null && _d !== void 0 ? _d : microphone_1.DefaultSampleRate);
        this.websocket = (_e = options.apiClient) !== null && _e !== void 0 ? _e : new websocket_1.WebsocketClient((_f = options.loginUrl) !== null && _f !== void 0 ? _f : defaultLoginUrl, (_g = options.apiUrl) !== null && _g !== void 0 ? _g : defaultApiUrl, language, (_h = options.sampleRate) !== null && _h !== void 0 ? _h : microphone_1.DefaultSampleRate);
        this.storage = (_j = options.storage) !== null && _j !== void 0 ? _j : new storage_1.LocalStorage();
        this.microphone.onAudio(this.handleMicrophoneAudio);
        this.websocket.onResponse(this.handleWebsocketResponse);
        this.websocket.onClose(this.handleWebsocketClosure);
    }
    /**
     * Initializes the client, by initializing the microphone and establishing connection to the API.
     *
     * This function HAS to be invoked by a user by e.g. binding it to a button press,
     * or some other user-performed action.
     *
     * If this function is invoked without a user interaction,
     * the microphone functionality will not work due to security restrictions by the browser.
     */
    initialize() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.state !== types_1.ClientState.Disconnected) {
                throw Error('Cannot initialize client - client is not in Disconnected state');
            }
            this.setState(types_1.ClientState.Connecting);
            try {
                // 1. Initialise the storage and fetch deviceId (or generate new one and store it).
                yield this.storage.initialize();
                this.deviceId = yield this.storage.getOrSet(deviceIdStorageKey, uuid_1.v4);
                // 2. Fetch auth token. It doesn't matter if it's not present.
                try {
                    this.authToken = yield this.storage.get(authTokenKey);
                }
                catch (err) {
                    if (this.debug) {
                        console.warn('[SpeechlyClient]', 'Error fetching auth token from storage:', err);
                    }
                }
                // 2. Initialise the microphone stack.
                yield this.microphone.initialize();
                // 3. Initialise websocket.
                yield this.initializeWebsocket(this.deviceId);
            }
            catch (err) {
                switch (err) {
                    case microphone_1.ErrDeviceNotSupported:
                        this.setState(types_1.ClientState.NoBrowserSupport);
                        break;
                    case microphone_1.ErrNoAudioConsent:
                        this.setState(types_1.ClientState.NoAudioConsent);
                        break;
                    default:
                        this.setState(types_1.ClientState.Failed);
                }
                throw err;
            }
            this.setState(types_1.ClientState.Connected);
        });
    }
    /**
     * Closes the client by closing the API connection and disabling the microphone.
     */
    close() {
        return __awaiter(this, void 0, void 0, function* () {
            const errs = [];
            try {
                yield this.storage.close();
            }
            catch (err) {
                errs.push(err.message);
            }
            try {
                yield this.microphone.close();
            }
            catch (err) {
                errs.push(err.message);
            }
            try {
                yield this.websocket.close();
            }
            catch (err) {
                errs.push(err.message);
            }
            this.activeContexts.clear();
            this.setState(types_1.ClientState.Disconnected);
            if (errs.length > 0) {
                throw Error(errs.join(','));
            }
        });
    }
    /**
     * Starts a new SLU context by sending a start context event to the API and unmuting the microphone.
     * @param cb - the callback which is invoked when the context start was acknowledged by the API.
     */
    startContext() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.resolveStopContext != null) {
                this.resolveStopContext();
                yield this.stoppedContextIdPromise;
            }
            if (this.state !== types_1.ClientState.Connected) {
                throw Error('Cannot start context - client is not connected');
            }
            this.setState(types_1.ClientState.Starting);
            let contextId;
            try {
                contextId = yield this.websocket.startContext();
            }
            catch (err) {
                this.setState(types_1.ClientState.Connected);
                throw err;
            }
            this.setState(types_1.ClientState.Recording);
            this.microphone.unmute();
            this.activeContexts.set(contextId, new Map());
            return contextId;
        });
    }
    /**
     * Stops current SLU context by sending a stop context event to the API and muting the microphone
     * delayed by contextStopDelay = 250 ms
     */
    stopContext() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.state !== types_1.ClientState.Recording) {
                throw Error('Cannot stop context - client is not recording');
            }
            this.setState(types_1.ClientState.Stopping);
            this.stoppedContextIdPromise = new Promise((resolve) => {
                Promise.race([
                    new Promise((resolve) => setTimeout(resolve, this.contextStopDelay)),
                    new Promise((resolve) => { this.resolveStopContext = resolve; }),
                ])
                    .then(() => {
                    this._stopContext()
                        .then(id => { resolve(id); })
                        .catch(err => { throw err; });
                })
                    .catch(err => { throw err; });
            });
            const contextId = yield this.stoppedContextIdPromise;
            this.setState(types_1.ClientState.Connected);
            this.activeContexts.delete(contextId);
            return contextId;
        });
    }
    _stopContext() {
        return __awaiter(this, void 0, void 0, function* () {
            this.microphone.mute();
            let contextId;
            try {
                contextId = yield this.websocket.stopContext();
            }
            catch (err) {
                this.setState(types_1.ClientState.Failed);
                throw err;
            }
            return contextId;
        });
    }
    /**
     * Adds a listener for client state change events.
     * @param cb - the callback to invoke on state change events.
     */
    onStateChange(cb) {
        this.stateChangeCb = cb;
    }
    /**
     * Adds a listener for current segment change events.
     * @param cb - the callback to invoke on segment change events.
     */
    onSegmentChange(cb) {
        this.segmentChangeCb = cb;
    }
    /**
     * Adds a listener for tentative transcript responses from the API.
     * @param cb - the callback to invoke on a tentative transcript response.
     */
    onTentativeTranscript(cb) {
        this.tentativeTranscriptCb = cb;
    }
    /**
     * Adds a listener for transcript responses from the API.
     * @param cb - the callback to invoke on a transcript response.
     */
    onTranscript(cb) {
        this.transcriptCb = cb;
    }
    /**
     * Adds a listener for tentative entities responses from the API.
     * @param cb - the callback to invoke on a tentative entities response.
     */
    onTentativeEntities(cb) {
        this.tentativeEntitiesCb = cb;
    }
    /**
     * Adds a listener for entity responses from the API.
     * @param cb - the callback to invoke on an entity response.
     */
    onEntity(cb) {
        this.entityCb = cb;
    }
    /**
     * Adds a listener for tentative intent responses from the API.
     * @param cb - the callback to invoke on a tentative intent response.
     */
    onTentativeIntent(cb) {
        this.tentativeIntentCb = cb;
    }
    /**
     * Adds a listener for intent responses from the API.
     * @param cb - the callback to invoke on an intent response.
     */
    onIntent(cb) {
        this.intentCb = cb;
    }
    reconnectWebsocket(deviceId) {
        return __awaiter(this, void 0, void 0, function* () {
            return async_retry_1.default((_, attempt) => __awaiter(this, void 0, void 0, function* () {
                if (this.debug) {
                    console.log('[SpeechlyClient]', 'WebSocket reconnection attempt number:', attempt);
                }
                yield this.initializeWebsocket(deviceId);
            }), {
                retries: this.reconnectAttemptCount,
                minTimeout: this.reconnectMinDelay,
            });
        });
    }
    initializeWebsocket(deviceId) {
        return __awaiter(this, void 0, void 0, function* () {
            // Initialise websocket and save the auth token.
            this.authToken = yield this.websocket.initialize(this.appId, deviceId, this.authToken);
            // Cache the auth token in local storage for future use.
            try {
                yield this.storage.set(authTokenKey, this.authToken);
            }
            catch (err) {
                // No need to fail if the token caching failed, we will just re-fetch it next time.
                if (this.debug) {
                    console.warn('[SpeechlyClient]', 'Error caching auth token in storage:', err);
                }
            }
        });
    }
    setState(newState) {
        if (this.state === newState) {
            return;
        }
        if (this.debug) {
            console.log('[SpeechlyClient]', 'State transition', state_1.stateToString(this.state), state_1.stateToString(newState));
        }
        this.state = newState;
        this.stateChangeCb(newState);
    }
}
exports.Client = Client;
//# sourceMappingURL=client.js.map