{"ast":null,"code":"\"use strict\";\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nconst types_1 = require(\"./types\");\n\nconst sampler_1 = require(\"./sampler\");\n\nconst audioProcessEvent = 'audioprocess';\nconst baseBufferSize = 4096;\n\nclass BrowserAudioProcessor {\n  constructor(sampleRate, onAudio, sampler) {\n    this.initialized = false;\n    this.muted = false;\n\n    this.handleAudio = event => {\n      if (this.muted) {\n        return;\n      }\n\n      this.onAudio(this.sampler.call(event.inputBuffer.getChannelData(0)));\n    };\n\n    try {\n      const constraints = window.navigator.mediaDevices.getSupportedConstraints();\n      this.nativeResamplingSupported = constraints.sampleRate === true;\n    } catch (_a) {\n      this.nativeResamplingSupported = false;\n    }\n\n    if (window.AudioContext !== undefined) {\n      const opts = {};\n\n      if (this.nativeResamplingSupported) {\n        opts.sampleRate = sampleRate;\n      }\n\n      this.audioContext = new window.AudioContext(opts);\n      this.isWebkit = false;\n    } else if (window.webkitAudioContext !== undefined) {\n      // eslint-disable-next-line new-cap\n      this.audioContext = new window.webkitAudioContext();\n      this.isWebkit = true;\n    } else {\n      throw types_1.ErrDeviceNotSupported;\n    }\n\n    this.sampler = sampler !== null && sampler !== void 0 ? sampler : sampler_1.newSampler(this.audioContext.sampleRate, sampleRate);\n    this.sampleRate = sampleRate;\n    this.onAudio = onAudio;\n  }\n\n  initialize() {\n    var _a;\n\n    return __awaiter(this, void 0, void 0, function* () {\n      if (((_a = window.navigator) === null || _a === void 0 ? void 0 : _a.mediaDevices) === undefined) {\n        throw types_1.ErrDeviceNotSupported;\n      } // Start audio context if we are dealing with a WebKit browser.\n      //\n      // WebKit browsers (e.g. Safari) require to resume the context first,\n      // before obtaining user media by calling `mediaDevices.getUserMedia`.\n      //\n      // If done in a different order, the audio context will resume successfully,\n      // but will emit empty audio buffers.\n\n\n      if (this.isWebkit) {\n        yield this.audioContext.resume();\n      }\n\n      try {\n        const opts = {\n          video: false\n        };\n\n        if (this.nativeResamplingSupported) {\n          opts.audio = {\n            sampleRate: this.sampleRate\n          };\n        } else {\n          opts.audio = true;\n        }\n\n        this.mediaStream = yield window.navigator.mediaDevices.getUserMedia(opts);\n      } catch (_b) {\n        throw types_1.ErrNoAudioConsent;\n      }\n\n      this.audioTrack = this.mediaStream.getAudioTracks()[0];\n      this.audioTrack.enabled = false; // Start audio context if we are dealing with a non-WebKit browser.\n      //\n      // Non-webkit browsers (currently only Chrome on Android)\n      // require that user media is obtained before resuming the audio context.\n      //\n      // If audio context is attempted to be resumed before `mediaDevices.getUserMedia`,\n      // `audioContext.resume()` will hang indefinitely, without being resolved or rejected.\n\n      if (!this.isWebkit) {\n        yield this.audioContext.resume();\n      }\n\n      if (this.isWebkit) {\n        // Multiply base buffer size of 4 kB by the resample ratio rounded up to the next power of 2.\n        // i.e. for 48 kHz to 16 kHz downsampling, this will be 4096 (base) * 4 = 16384.\n        const bufSize = baseBufferSize * Math.pow(2, Math.ceil(Math.log(this.sampler.resampleRatio) / Math.log(2)));\n        this.audioProcessor = this.audioContext.createScriptProcessor(bufSize, 1, 1);\n      } else {\n        this.audioProcessor = this.audioContext.createScriptProcessor(undefined, 1, 1);\n      }\n\n      this.audioContext.createMediaStreamSource(this.mediaStream).connect(this.audioProcessor);\n      this.audioProcessor.connect(this.audioContext.destination);\n      this.audioProcessor.addEventListener(audioProcessEvent, this.handleAudio);\n      this.initialized = true;\n    });\n  }\n\n  close() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!this.initialized) {\n        throw types_1.ErrNotInitialized;\n      } // Stop all media tracks\n\n\n      const stream = this.mediaStream;\n      stream.getTracks().forEach(t => t.stop()); // Disconnect and stop ScriptProcessorNode\n\n      const proc = this.audioProcessor;\n      proc.disconnect();\n      proc.removeEventListener(audioProcessEvent, this.handleAudio); // Unset all audio infrastructure\n\n      this.mediaStream = undefined;\n      this.audioTrack = undefined;\n      this.audioProcessor = undefined;\n      this.initialized = false;\n    });\n  }\n\n  mute() {\n    this.muted = true;\n\n    if (this.initialized) {\n      const t = this.audioTrack;\n      t.enabled = false;\n    }\n  }\n\n  unmute() {\n    this.muted = false;\n\n    if (this.initialized) {\n      const t = this.audioTrack;\n      t.enabled = true;\n    }\n  }\n\n}\n\nexports.BrowserAudioProcessor = BrowserAudioProcessor;","map":{"version":3,"sources":["../../src/microphone/browser_audio_processor.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,MAAA,OAAA,GAAA,OAAA,CAAA,SAAA,CAAA;;AACA,MAAA,SAAA,GAAA,OAAA,CAAA,WAAA,CAAA;;AAWA,MAAM,iBAAiB,GAAG,cAA1B;AACA,MAAM,cAAc,GAAG,IAAvB;;AAEA,MAAa,qBAAb,CAAkC;AAqBhC,EAAA,WAAA,CAAY,UAAZ,EAAgC,OAAhC,EAAuD,OAAvD,EAA4E;AApBpE,SAAA,WAAA,GAAuB,KAAvB;AACA,SAAA,KAAA,GAAiB,KAAjB;;AAuJS,SAAA,WAAA,GAAe,KAAD,IAAsC;AACnE,UAAI,KAAK,KAAT,EAAgB;AACd;AACD;;AAED,WAAK,OAAL,CAAa,KAAK,OAAL,CAAa,IAAb,CAAkB,KAAK,CAAC,WAAN,CAAkB,cAAlB,CAAiC,CAAjC,CAAlB,CAAb;AACD,KANgB;;AAnIf,QAAI;AACF,YAAM,WAAW,GAAG,MAAM,CAAC,SAAP,CAAiB,YAAjB,CAA8B,uBAA9B,EAApB;AACA,WAAK,yBAAL,GAAiC,WAAW,CAAC,UAAZ,KAA2B,IAA5D;AACD,KAHD,CAGE,OAAA,EAAA,EAAM;AACN,WAAK,yBAAL,GAAiC,KAAjC;AACD;;AAED,QAAI,MAAM,CAAC,YAAP,KAAwB,SAA5B,EAAuC;AACrC,YAAM,IAAI,GAAwB,EAAlC;;AACA,UAAI,KAAK,yBAAT,EAAoC;AAClC,QAAA,IAAI,CAAC,UAAL,GAAkB,UAAlB;AACD;;AAED,WAAK,YAAL,GAAoB,IAAI,MAAM,CAAC,YAAX,CAAwB,IAAxB,CAApB;AACA,WAAK,QAAL,GAAgB,KAAhB;AACD,KARD,MAQO,IAAI,MAAM,CAAC,kBAAP,KAA8B,SAAlC,EAA6C;AAClD;AACA,WAAK,YAAL,GAAoB,IAAI,MAAM,CAAC,kBAAX,EAApB;AACA,WAAK,QAAL,GAAgB,IAAhB;AACD,KAJM,MAIA;AACL,YAAM,OAAA,CAAA,qBAAN;AACD;;AAED,SAAK,OAAL,GAAe,OAAO,KAAA,IAAP,IAAA,OAAO,KAAA,KAAA,CAAP,GAAA,OAAA,GAAW,SAAA,CAAA,UAAA,CAAW,KAAK,YAAL,CAAkB,UAA7B,EAAyC,UAAzC,CAA1B;AACA,SAAK,UAAL,GAAkB,UAAlB;AACA,SAAK,OAAL,GAAe,OAAf;AACD;;AAEK,EAAA,UAAU,GAAA;;;;AACd,UAAI,CAAA,CAAA,EAAA,GAAA,MAAM,CAAC,SAAP,MAAgB,IAAhB,IAAgB,EAAA,KAAA,KAAA,CAAhB,GAAgB,KAAA,CAAhB,GAAgB,EAAA,CAAE,YAAlB,MAAmC,SAAvC,EAAkD;AAChD,cAAM,OAAA,CAAA,qBAAN;AACD,O,CAED;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,UAAI,KAAK,QAAT,EAAmB;AACjB,cAAM,KAAK,YAAL,CAAkB,MAAlB,EAAN;AACD;;AAED,UAAI;AACF,cAAM,IAAI,GAA2B;AACnC,UAAA,KAAK,EAAE;AAD4B,SAArC;;AAIA,YAAI,KAAK,yBAAT,EAAoC;AAClC,UAAA,IAAI,CAAC,KAAL,GAAa;AACX,YAAA,UAAU,EAAE,KAAK;AADN,WAAb;AAGD,SAJD,MAIO;AACL,UAAA,IAAI,CAAC,KAAL,GAAa,IAAb;AACD;;AAED,aAAK,WAAL,GAAmB,MAAM,MAAM,CAAC,SAAP,CAAiB,YAAjB,CAA8B,YAA9B,CAA2C,IAA3C,CAAzB;AACD,OAdD,CAcE,OAAA,EAAA,EAAM;AACN,cAAM,OAAA,CAAA,iBAAN;AACD;;AAED,WAAK,UAAL,GAAkB,KAAK,WAAL,CAAiB,cAAjB,GAAkC,CAAlC,CAAlB;AACA,WAAK,UAAL,CAAgB,OAAhB,GAA0B,KAA1B,C,CAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,UAAI,CAAC,KAAK,QAAV,EAAoB;AAClB,cAAM,KAAK,YAAL,CAAkB,MAAlB,EAAN;AACD;;AAED,UAAI,KAAK,QAAT,EAAmB;AACjB;AACA;AACA,cAAM,OAAO,GAAG,cAAc,GAAG,IAAI,CAAC,GAAL,CAAS,CAAT,EAAY,IAAI,CAAC,IAAL,CAAU,IAAI,CAAC,GAAL,CAAS,KAAK,OAAL,CAAa,aAAtB,IAAuC,IAAI,CAAC,GAAL,CAAS,CAAT,CAAjD,CAAZ,CAAjC;AACA,aAAK,cAAL,GAAsB,KAAK,YAAL,CAAkB,qBAAlB,CAAwC,OAAxC,EAAiD,CAAjD,EAAoD,CAApD,CAAtB;AACD,OALD,MAKO;AACL,aAAK,cAAL,GAAsB,KAAK,YAAL,CAAkB,qBAAlB,CAAwC,SAAxC,EAAmD,CAAnD,EAAsD,CAAtD,CAAtB;AACD;;AAED,WAAK,YAAL,CAAkB,uBAAlB,CAA0C,KAAK,WAA/C,EAA4D,OAA5D,CAAoE,KAAK,cAAzE;AACA,WAAK,cAAL,CAAoB,OAApB,CAA4B,KAAK,YAAL,CAAkB,WAA9C;AACA,WAAK,cAAL,CAAoB,gBAApB,CAAqC,iBAArC,EAAwD,KAAK,WAA7D;AAEA,WAAK,WAAL,GAAmB,IAAnB;;AACD;;AAEK,EAAA,KAAK,GAAA;;AACT,UAAI,CAAC,KAAK,WAAV,EAAuB;AACrB,cAAM,OAAA,CAAA,iBAAN;AACD,O,CAED;;;AACA,YAAM,MAAM,GAAG,KAAK,WAApB;AACA,MAAA,MAAM,CAAC,SAAP,GAAmB,OAAnB,CAA2B,CAAC,IAAI,CAAC,CAAC,IAAF,EAAhC,E,CAEA;;AACA,YAAM,IAAI,GAAG,KAAK,cAAlB;AACA,MAAA,IAAI,CAAC,UAAL;AACA,MAAA,IAAI,CAAC,mBAAL,CAAyB,iBAAzB,EAA4C,KAAK,WAAjD,E,CAEA;;AACA,WAAK,WAAL,GAAmB,SAAnB;AACA,WAAK,UAAL,GAAkB,SAAlB;AACA,WAAK,cAAL,GAAsB,SAAtB;AACA,WAAK,WAAL,GAAmB,KAAnB;AACD,K;AAAA;;AAED,EAAA,IAAI,GAAA;AACF,SAAK,KAAL,GAAa,IAAb;;AAEA,QAAI,KAAK,WAAT,EAAsB;AACpB,YAAM,CAAC,GAAG,KAAK,UAAf;AACA,MAAA,CAAC,CAAC,OAAF,GAAY,KAAZ;AACD;AACF;;AAED,EAAA,MAAM,GAAA;AACJ,SAAK,KAAL,GAAa,KAAb;;AAEA,QAAI,KAAK,WAAT,EAAsB;AACpB,YAAM,CAAC,GAAG,KAAK,UAAf;AACA,MAAA,CAAC,CAAC,OAAF,GAAY,IAAZ;AACD;AACF;;AAvJ+B;;AAAlC,OAAA,CAAA,qBAAA,GAAA,qBAAA","sourceRoot":"","sourcesContent":["\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst types_1 = require(\"./types\");\nconst sampler_1 = require(\"./sampler\");\nconst audioProcessEvent = 'audioprocess';\nconst baseBufferSize = 4096;\nclass BrowserAudioProcessor {\n    constructor(sampleRate, onAudio, sampler) {\n        this.initialized = false;\n        this.muted = false;\n        this.handleAudio = (event) => {\n            if (this.muted) {\n                return;\n            }\n            this.onAudio(this.sampler.call(event.inputBuffer.getChannelData(0)));\n        };\n        try {\n            const constraints = window.navigator.mediaDevices.getSupportedConstraints();\n            this.nativeResamplingSupported = constraints.sampleRate === true;\n        }\n        catch (_a) {\n            this.nativeResamplingSupported = false;\n        }\n        if (window.AudioContext !== undefined) {\n            const opts = {};\n            if (this.nativeResamplingSupported) {\n                opts.sampleRate = sampleRate;\n            }\n            this.audioContext = new window.AudioContext(opts);\n            this.isWebkit = false;\n        }\n        else if (window.webkitAudioContext !== undefined) {\n            // eslint-disable-next-line new-cap\n            this.audioContext = new window.webkitAudioContext();\n            this.isWebkit = true;\n        }\n        else {\n            throw types_1.ErrDeviceNotSupported;\n        }\n        this.sampler = sampler !== null && sampler !== void 0 ? sampler : sampler_1.newSampler(this.audioContext.sampleRate, sampleRate);\n        this.sampleRate = sampleRate;\n        this.onAudio = onAudio;\n    }\n    initialize() {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            if (((_a = window.navigator) === null || _a === void 0 ? void 0 : _a.mediaDevices) === undefined) {\n                throw types_1.ErrDeviceNotSupported;\n            }\n            // Start audio context if we are dealing with a WebKit browser.\n            //\n            // WebKit browsers (e.g. Safari) require to resume the context first,\n            // before obtaining user media by calling `mediaDevices.getUserMedia`.\n            //\n            // If done in a different order, the audio context will resume successfully,\n            // but will emit empty audio buffers.\n            if (this.isWebkit) {\n                yield this.audioContext.resume();\n            }\n            try {\n                const opts = {\n                    video: false,\n                };\n                if (this.nativeResamplingSupported) {\n                    opts.audio = {\n                        sampleRate: this.sampleRate,\n                    };\n                }\n                else {\n                    opts.audio = true;\n                }\n                this.mediaStream = yield window.navigator.mediaDevices.getUserMedia(opts);\n            }\n            catch (_b) {\n                throw types_1.ErrNoAudioConsent;\n            }\n            this.audioTrack = this.mediaStream.getAudioTracks()[0];\n            this.audioTrack.enabled = false;\n            // Start audio context if we are dealing with a non-WebKit browser.\n            //\n            // Non-webkit browsers (currently only Chrome on Android)\n            // require that user media is obtained before resuming the audio context.\n            //\n            // If audio context is attempted to be resumed before `mediaDevices.getUserMedia`,\n            // `audioContext.resume()` will hang indefinitely, without being resolved or rejected.\n            if (!this.isWebkit) {\n                yield this.audioContext.resume();\n            }\n            if (this.isWebkit) {\n                // Multiply base buffer size of 4 kB by the resample ratio rounded up to the next power of 2.\n                // i.e. for 48 kHz to 16 kHz downsampling, this will be 4096 (base) * 4 = 16384.\n                const bufSize = baseBufferSize * Math.pow(2, Math.ceil(Math.log(this.sampler.resampleRatio) / Math.log(2)));\n                this.audioProcessor = this.audioContext.createScriptProcessor(bufSize, 1, 1);\n            }\n            else {\n                this.audioProcessor = this.audioContext.createScriptProcessor(undefined, 1, 1);\n            }\n            this.audioContext.createMediaStreamSource(this.mediaStream).connect(this.audioProcessor);\n            this.audioProcessor.connect(this.audioContext.destination);\n            this.audioProcessor.addEventListener(audioProcessEvent, this.handleAudio);\n            this.initialized = true;\n        });\n    }\n    close() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.initialized) {\n                throw types_1.ErrNotInitialized;\n            }\n            // Stop all media tracks\n            const stream = this.mediaStream;\n            stream.getTracks().forEach(t => t.stop());\n            // Disconnect and stop ScriptProcessorNode\n            const proc = this.audioProcessor;\n            proc.disconnect();\n            proc.removeEventListener(audioProcessEvent, this.handleAudio);\n            // Unset all audio infrastructure\n            this.mediaStream = undefined;\n            this.audioTrack = undefined;\n            this.audioProcessor = undefined;\n            this.initialized = false;\n        });\n    }\n    mute() {\n        this.muted = true;\n        if (this.initialized) {\n            const t = this.audioTrack;\n            t.enabled = false;\n        }\n    }\n    unmute() {\n        this.muted = false;\n        if (this.initialized) {\n            const t = this.audioTrack;\n            t.enabled = true;\n        }\n    }\n}\nexports.BrowserAudioProcessor = BrowserAudioProcessor;\n//# sourceMappingURL=browser_audio_processor.js.map"]},"metadata":{},"sourceType":"script"}